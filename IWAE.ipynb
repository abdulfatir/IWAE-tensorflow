{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importance Weighted Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_dim = 50\n",
    "batch_size = 100\n",
    "nb_steps = 400000\n",
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def render_images(np_x):\n",
    "    np_x = np_x.reshape((10,10,28,28))\n",
    "    np_x = np.concatenate(np.split(np_x,10,axis=0),axis=3)\n",
    "    np_x = np.concatenate(np.split(np_x,10,axis=1),axis=2)\n",
    "    x_img = np.squeeze(np_x)\n",
    "    plt.imshow(x_img, cmap='Greys_r')\n",
    "    plt.title('Generation')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encoder(x, z_dim=20, reuse=False):\n",
    "    with tf.variable_scope(\"encoder\", reuse=reuse):\n",
    "        l1 = tf.layers.dense(x, 200, activation=tf.nn.relu)\n",
    "        l2 = tf.layers.dense(l1, 200, activation=tf.nn.relu)\n",
    "        mu = tf.layers.dense(l2, z_dim, activation=None)\n",
    "        sigma = 1e-6 + tf.nn.softplus(tf.layers.dense(l2, z_dim, activation=None))\n",
    "        return mu, sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decoder(z, z_dim=20, reuse=False):\n",
    "    with tf.variable_scope(\"decoder\", reuse=reuse):\n",
    "        l1 = tf.layers.dense(z, 200, activation=tf.nn.relu)\n",
    "        l2 = tf.layers.dense(l1, 200, activation=tf.nn.relu)\n",
    "        x_hat = tf.layers.dense(l2, 784, activation=tf.nn.sigmoid)\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(z, mu, sigma, x, x_hat, training=True):\n",
    "    log2pi = tf.log(2 * np.pi)\n",
    "    log_QzGx = (-(z_dim / 2)*log2pi \n",
    "                + tf.reduce_sum(- tf.log(sigma) - 0.5 * tf.squared_difference(z, mu) / (2 * tf.square(sigma)), -1))\n",
    "    log_PxGz = tf.reduce_mean(tf.reduce_sum(x * tf.log(x_hat + 1e-8) + (1 - x) * tf.log(1 - x_hat + 1e-8), [1]))\n",
    "    log_Pz = (-(z_dim / 2)*log2pi \n",
    "                + tf.reduce_sum(- 0.5 * tf.squared_difference(z, 0) / 2, -1))\n",
    "    if training:\n",
    "        log_weights = tf.reshape(log_PxGz + log_Pz - log_QzGx, [k, batch_size])\n",
    "        weights = tf.exp(log_weights - tf.reduce_max(log_weights, 0))\n",
    "        normalized_weights = weights / tf.reduce_sum(weights, 0)\n",
    "        loss = -tf.reduce_mean(tf.reduce_sum(normalized_weights * log_weights, 0))\n",
    "    else:\n",
    "        log_weights = tf.reshape(log_PxGz + log_Pz - log_QzGx, [5000, 1])\n",
    "        log_wmax = tf.reduce_max(log_weights, 0)\n",
    "        weights = tf.exp(log_weights - log_wmax)\n",
    "        loss = -tf.reduce_mean(tf.log(tf.reduce_mean(weights, 0))) -tf.reduce_mean(log_wmax)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.placeholder(tf.float32, [batch_size, 784])\n",
    "x_k = tf.tile(x, [k, 1])\n",
    "mu, sigma = encoder(x_k, z_dim=z_dim)\n",
    "z = mu + sigma * tf.random_normal([k * batch_size, z_dim], 0, 1, dtype=tf.float32)\n",
    "x_hat = decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = objective(z, mu, sigma, x_k, x_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = tf.placeholder(tf.float32, [1, 784])\n",
    "x_k_test = tf.tile(x_test, [5000, 1])\n",
    "mu_test, sigma_test = encoder(x_k_test, z_dim=z_dim, reuse=True)\n",
    "z_test = mu_test + sigma_test * tf.random_normal([5000 * 1, z_dim], 0, 1, dtype=tf.float32)\n",
    "x_hat_test = decoder(z_test, reuse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss = objective(z_test, mu_test, sigma_test, x_k_test, x_hat_test, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optim_op = tf.train.AdamOptimizer(1e-4).minimize(loss)\n",
    "init_op = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.InteractiveSession(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"/tmp/data/\", one_hot=True, reshape=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.run(init_op)\n",
    "start_time = time.time()\n",
    "for stp in range(1, nb_steps+1):\n",
    "    x_np, _ = mnist.train.next_batch(batch_size)\n",
    "    _, loss_np = sess.run([optim_op, loss], feed_dict={x: x_np})\n",
    "    if stp % 5000 == 0:\n",
    "        end_time = time.time()\n",
    "        print('Step: {:d} in {:.2f}s :: Loss: {:.3f}'.format(stp, end_time - start_time, loss_np))\n",
    "        start_time = end_time\n",
    "        x_hat_np = sess.run(x_hat, feed_dict={x: mnist.train.next_batch(100)[0]})\n",
    "        render_images(x_hat_np[:100])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
